{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Educat8n/AI-Development-Oxford/blob/main/Cancer_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7AWhJmKKUmp"
      },
      "source": [
        "# Step 1\n",
        "\n",
        "Write the code in a python file using magic command `%%writefile`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6CEot9f_zE_",
        "outputId": "fdc63e1b-46ae-4150-ae12-4cb59cf8e0a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing cancer_detection.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile cancer_detection.py\n",
        "\n",
        "\n",
        "# Step -1 - Import Package\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
        "\n",
        "\n",
        "\n",
        "# Step - 2 - Define the main function\n",
        "def main():\n",
        "    # Get data\n",
        "    cancer_data = load_breast_cancer()\n",
        "    \n",
        "    cancer_data_X = pd.DataFrame(cancer_data.data, columns = cancer_data.feature_names)\n",
        "    cancer_data_y = cancer_data.target\n",
        "    features = cancer_data.feature_names\n",
        "    \n",
        "    vars = ['mean radius', 'mean texture', 'mean area', 'mean perimeter', 'mean smoothness']\n",
        "    ## Data Exploration\n",
        "    print(f'The features in dataset are: {features}')\n",
        "    #print(f'Data description\\n {cancer_data_X.describe()}')\n",
        "    \n",
        "    #Plots\n",
        "    plot_data(cancer_data_X, cancer_data_y, features= vars, cor=True)\n",
        "\n",
        "    ## Remove Outliers\n",
        "    cancer_data_X, cancer_data_y = remove_outliers(cancer_data_X,cancer_data_y, features)\n",
        "    \n",
        "    X_train, y_train, X_test, y_test = preprocess(cancer_data_X, cancer_data_y, features)\n",
        "    model = SVC(random_state=6)\n",
        "\n",
        "    model = train(model, X_train, y_train)\n",
        "    \n",
        "    baseline = evaluate(model, X_test, y_test, bl=True)\n",
        "\n",
        "    best_params = optimize_models(X_train, y_train)\n",
        "    print(best_params)\n",
        "\n",
        "    ## Build Best Model\n",
        "    best_C= best_params['C']\n",
        "    best_kernel = best_params['kernel']\n",
        "\n",
        "    best_model = SVC(kernel = best_kernel, C= best_C, random_state=6)\n",
        "    best_model = train(best_model, X_train, y_train)\n",
        "    evaluate (best_model, X_test, y_test)\n",
        "    \n",
        "\n",
        " \n",
        "    \n",
        "    \n",
        "# Step - 3 - Plot graphs to understand data\n",
        "def plot_data(x_df, y_df,features, cor=False):\n",
        "    X = x_df.copy(deep=True)\n",
        "    X['class'] = y_df\n",
        "    sns.pairplot(X, hue = 'class', vars = ['mean radius', 'mean texture', 'mean area', 'mean perimeter', 'mean smoothness'] )\n",
        "    plt.show()\n",
        "    \n",
        "    if cor:\n",
        "      corr = X[features].corr()\n",
        "      plt.figure(figsize=(10,10))\n",
        "      sns.heatmap(corr, cbar=True, square= True, fmt='.1f', annot=True, annot_kws={'size':15}, cmap='Greens')\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Step - 4 - Preprocess data\n",
        "# Step -4a : Remove outliers\n",
        "def remove_outliers(x,y, features):\n",
        "    #remove null\n",
        "    x_df = x.copy(deep=True)\n",
        "    x_df['class'] = y\n",
        "    x_df.dropna(inplace=True)\n",
        "    return x_df[features], x_df['class']\n",
        "    \n",
        "    \n",
        "# Step -4b : Normalize data\n",
        "def scale_numeric(df):\n",
        "    x = df.values \n",
        "    scaler = preprocessing.StandardScaler()\n",
        "    x_scaled = scaler.fit_transform(x)\n",
        "    df = pd.DataFrame(x_scaled)\n",
        "    return df\n",
        "\n",
        "    \n",
        "\n",
        "# Step -4b : Preprocess data\n",
        "def preprocess(x, y, features):\n",
        "    x_df = x[features].copy(deep=True)\n",
        "    x_df = scale_numeric(x_df)\n",
        "    #print(len(x_df),len(y))\n",
        "    # Split data into train, test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x_df,y, test_size=0.3, random_state=45)\n",
        "    return X_train, y_train, X_test, y_test\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "# Step - 5 - train model \n",
        "def train(model,X_train, y_train):\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "    \n",
        "    \n",
        "# Step - 6 - Evaluate Model\n",
        "def evaluate(model, X_test, y_test, plot = True, print_results=True, bl=False):\n",
        "    y_pred = model.predict(X_test)\n",
        "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "    acc = metrics.accuracy_score(y_test, y_pred)\n",
        "    if print_results:\n",
        "      if bl:\n",
        "        print('\\n\\nBaseline Model Performance on Test Dataset:\\n')\n",
        "      else:\n",
        "        print('\\n\\nBest Model Performance on Test Dataset:\\n')\n",
        "      print('\\nConfusion Matrix:\\n',cm)\n",
        "      print(f'Accuracy: {acc*100}%')\n",
        "\n",
        "    if plot:\n",
        "      sns.heatmap(cm, annot= True)\n",
        "      plt.show()\n",
        "    return \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "# Step - 7 - Improve Model\n",
        "def optimize_models(X_train, y_train):\n",
        "  params = {'kernel':['rbf'], 'C':[1.0, 5.0, 10]}\n",
        "  model = SVC(random_state=5)\n",
        "  clf = GridSearchCV(model, params)\n",
        "  clf.fit(X_train, y_train)\n",
        "  return clf.best_params_\n",
        "\n",
        "\n",
        "# call the main finction\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "    \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sMfZj7oKhES"
      },
      "source": [
        "# Step 2 \n",
        "\n",
        "Run the python command using magic command `%run` followed by the python file name "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RwUe0B6NEtb8",
        "outputId": "d0bb1701-cf7f-4eb4-c23f-a9383cef9dcc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hijik\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The features in dataset are: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1308.88x1250 with 30 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Baseline Model Performance on Test Dataset:\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 57   4]\n",
            " [  1 109]]\n",
            "Accuracy: 97.07602339181285%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'C': 5.0, 'kernel': 'rbf'}\n",
            "\n",
            "\n",
            "Best Model Performance on Test Dataset:\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 59   2]\n",
            " [  0 110]]\n",
            "Accuracy: 98.83040935672514%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%run cancer_detection.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwrKte3d5GBa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyO9nF3azmsmPeOutscu7DX6",
      "include_colab_link": true,
      "name": "Cancer_detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
